{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "In this notebook we will implement some dataset analysis techniques to integrate into Suggester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modules\n",
    "import importlib\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import modules.models.Linear as Linear\n",
    "from modules.ActiveLearning import Samplings\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from modules import ActiveLearning\n",
    "from modules import Suggester\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "importlib.reload(modules)\n",
    "importlib.reload(modules.models.Linear)\n",
    "importlib.reload(modules.ActiveLearning)\n",
    "importlib.reload(modules.Suggester)\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainConfusion:\n",
    "    def __init__(self, top_n=10):\n",
    "        self.top_n = top_n\n",
    "\n",
    "    def get_most_frequently_confused_classes(self, model, X_train, y_train):\n",
    "        y_pred = model.predict(X_train)\n",
    "        conf_dict = {}\n",
    "        for real, pred in zip(y_train, y_pred):\n",
    "            if (real != pred):\n",
    "                mask = (real,pred)\n",
    "                conf_dict[mask] = conf_dict.get(mask, 0) + 1\n",
    "        lst = list(conf_dict.items())\n",
    "        lst = sorted(lst, key=lambda x: -1 * (conf_dict.get((x[0][1],x[0][0]),0) + x[1]))\n",
    "        tmp = {}\n",
    "        successfully_added = 0\n",
    "        for key, val in lst:\n",
    "            if successfully_added >= self.top_n:\n",
    "                break\n",
    "            if (tmp.get((key[1],key[0]),-1) == -1):\n",
    "                tmp[key] = (val, conf_dict.get((key[1], key[0]),0))\n",
    "                successfully_added += 1\n",
    "        return tmp\n",
    "    \n",
    "    def pretty_print(self, model, X_train, y_train):\n",
    "        tmp = self.get_most_frequently_confused_classes(model, X_train, y_train)\n",
    "        for key, value in tmp.items():\n",
    "            print(f\"{key[0]} was mistaken for {key[1]} {value[0]} times and {key[1]} for {key[0]} {value[1]} times\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindZeroSamples:\n",
    "    def __init__(self):\n",
    "        self.epsilon = 1e-7\n",
    "    \n",
    "    def get_zero_samples_count(self, X):\n",
    "        print(np.argwhere(np.all(abs(X) < self.epsilon, axis=1)))\n",
    "        return np.count_nonzero(np.all(abs(X) < self.epsilon, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset():\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    vectorized_output_path = \"selfpost/vectorized.npy\"\n",
    "    vectorized_labels_output_path = \"selfpost/vectorized_labels.npy\"\n",
    "    with open(vectorized_output_path, \"rb\") as vect_X, open(vectorized_labels_output_path, \"rb\") as vect_y:\n",
    "        X = np.load(vect_X, allow_pickle=True)\n",
    "        y = np.load(vect_y, allow_pickle=True)\n",
    "    le.fit(y)\n",
    "    y = le.transform(y)\n",
    "    return X, y, le.get_params() \n",
    "\n",
    "X, y, y_dict = import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 50009.59it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "random.seed(random_seed)\n",
    "sug = Suggester.Suggester(X,y, test_fraction=0.99)\n",
    "model = Linear.LinearModelTorch(Linear.LogReg(), 100)\n",
    "model.train(sug.X_train, sug.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tconf = TrainConfusion(20)\n",
    "tconf.pretty_print(model, sug.X_train, sug.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispute measure: how much n_nearest nearest points' known class counts are unbalanced\n",
    "# Не уверен, как это впихнуть в саджестр, потому что не совпадает интерфейс с остальными\n",
    "# методами активлернинга. Возможно, я передаю интерфейс get_samples_for_labeling и буду \n",
    "# передавать туда сам suggester\n",
    "class LabelDisputablePoints:\n",
    "    def __init__(self, n_top=1000, n_nearest=100):\n",
    "        self.n_top = n_top\n",
    "        self.n_nearest = n_nearest\n",
    "        \n",
    "# Придумать более адекватную реализацию)\n",
    "    def get_samples_for_labeling(self, sug, X_test, y_test):\n",
    "        print(X_test.shape, y_test.shape)\n",
    "        dist, ind = sug.index.search(sug.X_test, self.n_nearest)\n",
    "        entropies = np.zeros(sug.X.shape[0], np.float32)\n",
    "        for i, idx in tqdm(enumerate(ind)):\n",
    "            mask = np.zeros(sug.X.shape[0], np.bool)\n",
    "            mask[idx] = True\n",
    "            mask = mask * sug.is_train_mask\n",
    "            neigh = np.bincount(sug.y[mask])\n",
    "            entropies[i] = entropy(neigh, axis=0)\n",
    "        indices_to_return = np.argsort(entropies)[::-1]\n",
    "        return indices_to_return[:self.n_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss import IndexFlatL2\n",
    "from modAL.models.base import BaseEstimator\n",
    "from modAL.utils.data import modALinput\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def _nearest_neighbours_to_entropy(nearest_neighbours: np.ndarray, min_bins: int):\n",
    "    bin_count = np.apply_along_axis(partial(np.bincount, minlength=min_bins), 1, nearest_neighbours)\n",
    "    return entropy(bin_count, axis=1)\n",
    "\n",
    "\n",
    "def classifier_train_confusion(classifier: BaseEstimator, X: modALinput,\n",
    "                               index: IndexFlatL2, n_nearest: int = 100,\n",
    "                               n_instances: int = 1, random_tie_break: bool = False,\n",
    "                               **uncertainty_measure_kwargs):\n",
    "    dist, ind = index.search(X, n_nearest)\n",
    "    entropies = _nearest_neighbours_to_entropy(classifier.y_training[ind], np.unique(classifier.y_training).shape[0])\n",
    "    indices_to_return = np.argsort(entropies)[::-1]\n",
    "    return indices_to_return[:n_instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_elements = 100000\n",
    "subsample = np.random.choice(X.shape[0], num_of_elements, replace=False)\n",
    "sug = Suggester.Suggester(X[subsample],y[subsample], test_fraction=0.8, build_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldp = LabelDisputablePoints()\n",
    "ldp.get_samples_for_labeling(sug, sug.X_test, sug.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.09861229, 0.63651417])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1, 1, 1], [1, 2, 3], [1, 2, 2]])\n",
    "_nearest_neighbours_to_entropy(arr, min_bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import entropy_sampling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from modules.models import Linear\n",
    "importlib.reload(Linear)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, train_size=0.01, random_state=random_seed)\n",
    "index = faiss.IndexFlatL2(X_test.shape[1])\n",
    "index.add(X_train.astype(np.float32))\n",
    "\n",
    "learner = ActiveLearner(\n",
    "    estimator=Linear.LinearModelTorch(Linear.LogReg(), 100),\n",
    "    query_strategy=classifier_train_confusion,\n",
    "    X_training=X_train, y_training=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idx, query_inst = learner.query(X_test.astype(np.float32), index=index, n_instances=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57438  47534  17361  56281  55553  50680  16802  52674  50242  70260\n",
      "  53060  71813  60726  40455  70972  56816  50172  83366  67631  30613\n",
      "  98789  97989  33731  36447  55315  16865 100338   4367   4992  17184\n",
      "  63143  16705  64433  29503  37309  42989  68123  57645  16925  15182\n",
      "  88186  86248  96934  48148  70632  89089  42561  94993  11871  62771\n",
      "  90671  54461  71559  23168  38862  45270  86572  62658  47845  80249\n",
      "  31005   5433  12292  27428  42143   6954   7029  42073  44592  16587\n",
      "  60016  92934  11210  71787  21243  20364  28385  18567   1148  89075\n",
      "  56296  17103    848  43754  61463   9523  30271  55540  57215  14670\n",
      "  59491  68820  56912   4014  30474  96031  23807  10289  18179  56291]\n"
     ]
    }
   ],
   "source": [
    "print(query_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabeling(ActiveLearningBase):\n",
    "    def __init__(self, n_top=1000):\n",
    "        super().__init__(n_top)\n",
    "        self.n_top = n_top\n",
    "\n",
    "    def get_samples_for_labeling(self, model, X_test, y_test):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        max_ind = np.argmax(y_proba, axis=1)\n",
    "        y_proba = np.max(y_proba, axis=1)\n",
    "        ind = np.lexsort((max_ind, y_proba))[::-1]\n",
    "        ind_to_return = ind[:min(self.n_top, y_proba.shape[0])]\n",
    "        return \"labeling\", ind_to_return, max_ind[ind_to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_pseudolabeling(classifier: BaseEstimator, X: modALinput, \n",
    "                               n_nearest: int = 100,\n",
    "                               n_instances: int = 1, random_tie_break: bool = False,\n",
    "                               **uncertainty_measure_kwargs):\n",
    "        y_proba = classifier.predict_proba(X)\n",
    "        entropies = entropy(y_proba, axis=1)\n",
    "        ind = np.argsort(entropies)\n",
    "        return ind[:n_instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.38it/s]\n"
     ]
    }
   ],
   "source": [
    "learner = ActiveLearner(\n",
    "    estimator=Linear.LinearModelTorch(Linear.LogReg(), 100),\n",
    "    query_strategy=classifier_pseudolabeling,\n",
    "    X_training=X_train, y_training=y_train\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27666   5341  55109  54160  38441  86666  53797  42529  24680  32840\n",
      "  20845  75265  81582  23898  87102  81589  10828  32101  75743  50718\n",
      "  17767  10730  92555  37968  56495  91285  25682   1525  26884  17762\n",
      "  41728  78060  40913  89181  75707   6001  81740  60742   3640  88635\n",
      "  68236  39517  86243  52512   2552  31827  14612   3879  22031  57727\n",
      "  62354  42808  27645  88267  79922  35362  46768  32552  14260  74931\n",
      "  11041  44516  87013  16093  38415  51698  32317  68217  80316  56618\n",
      "  24924   3114  50981  63565 100303  51363  12105   8957  33177  44945\n",
      "  98491  43848  78913  39102  49669  61121   6443  19048  24463  72725\n",
      "  27218  44396  10446  21445  52798  72248  20801  13735  83742  96758]\n"
     ]
    }
   ],
   "source": [
    "query_idx, query_inst = learner.query(X_test.astype(np.float32), index=index, n_instances=100)\n",
    "print(query_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
