{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TOPAPEC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules.ModelWrap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f621c4d92f6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActiveLearning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mActiveLearning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelWrap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelWrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActiveLearningBase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mActiveLearningBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSuggester\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSuggester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'modules.ModelWrap'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import faiss\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import modules\n",
    "import pickle\n",
    "import sys\n",
    "import numpy\n",
    "import logging\n",
    "import modules.ActiveLearning as ActiveLearning\n",
    "import modules.preprocess as preprocess\n",
    "from modules.ModelWrap import ModelWrap\n",
    "from modules.ActiveLearningBase import ActiveLearningBase\n",
    "from modules.Suggester import Suggester\n",
    "from modules.Suggest import Suggest\n",
    "importlib.reload(modules)\n",
    "importlib.reload(modules.Suggest)\n",
    "importlib.reload(modules.Suggester)\n",
    "importlib.reload(modules.ActiveLearningBase)\n",
    "importlib.reload(modules.ActiveLearning)\n",
    "importlib.reload(preprocess)\n",
    "from tqdm import tqdm\n",
    "from joblib import dump, load\n",
    "from multiprocessing import Pool\n",
    "from sklearn import preprocessing\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=100000)\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOPAPEC\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# This time we are using reddit self-post classification dataset https://www.kaggle.com/mswarbrickjones/reddit-selfposts/?select=subreddit_info.csv\n",
    "# We will assume that post title and post body can be concatenated into one text column.\n",
    "embeddings_dim = 300\n",
    "tqdm.pandas()\n",
    "\n",
    "def preprocess_and_save_dataset(dataset_path, preprocessed_path):\n",
    "    dataframe = pd.read_csv(dataset_path, sep='\\t')\n",
    "    dataframe.loc[:, \"text\"] = dataframe.loc[:, \"title\"] + \" \" + dataframe.loc[:, \"selftext\"]\n",
    "    dataframe = dataframe.drop([\"title\", \"selftext\"], axis=1)\n",
    "    preprocess_pipeline(dataframe)\n",
    "    dataframe.to_pickle(preprocessed_path)\n",
    "    del dataframe\n",
    "\n",
    "def vectorize_and_save_dataset(pickle_path, output_path, output_path_labels):\n",
    "    dataset = pd.read_pickle(pickle_path)\n",
    "    vectorized = np.zeros((dataset.shape[0], embeddings_dim))\n",
    "    embeddings = get_glove_reddit_embeddings()\n",
    "    for i, (vec, row) in enumerate(zip(vectorized, dataset.iterrows())):\n",
    "        vectorized[i] = preprocess.row_to_embedding(row, embeddings, embeddings_dim)\n",
    "    del embeddings\n",
    "    with open(output_path, \"wb\") as file:\n",
    "        np.save(file, vectorized)\n",
    "    with open(output_path_labels, \"wb\") as file:\n",
    "        np.save(file, dataset.loc[:, \"subreddit\"].to_numpy())\n",
    "    del dataset\n",
    "\n",
    "    \n",
    "def preprocess_pipeline(dataset):\n",
    "    cores = 12\n",
    "    multicore_tok(dataset, cores)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    dataset.loc[:, \"text\"].progress_apply(lemmatize_sent, args=[wnl])\n",
    "\n",
    "def lemmatize_sent(wordlist, wnl):\n",
    "    return ' '.join([wnl.lemmatize(w) for w in wordlist])\n",
    "    \n",
    "def multicore_tok(dataset, cores=6):\n",
    "    with Pool(processes=cores) as pool:\n",
    "        dataset.loc[:, \"text\"] = pool.map(nltk.word_tokenize, dataset.loc[:, \"text\"])\n",
    "\n",
    "def multicore_lem(dataset, cores=6):\n",
    "    with Pool(processes=cores) as pool:\n",
    "        wnl = WordNetLemmatizer()\n",
    "        for i, line in tqdm(enumerate(dataset.text)):\n",
    "            dataset.loc[i,\"text\"] = pool.map(wnl.lemmatize, dataset.loc[i, \"text\"])\n",
    "            \n",
    "def get_glove_reddit_embeddings():\n",
    "    # Number of words - 1623397 \n",
    "    embeddings = {}\n",
    "    tmp = []\n",
    "    with io.open(\"GloVe.Reddit.120B.300D.txt\", \"r\", encoding='utf-8') as file:\n",
    "        file.readline()\n",
    "        for line in tqdm(file, total=1623397):\n",
    "            tmp.append(line)\n",
    "    with Pool(processes=14) as pool:\n",
    "        tmp = list(tqdm(pool.imap(preprocess.fetch_embeddings_value, tmp, chunksize=200000), total=1623397))\n",
    "    for word, vector in tqdm(tmp):\n",
    "        embeddings[word] = vector\n",
    "    del tmp\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"selfpost/rspct.tsv\"\n",
    "preprocessed_path = \"selfpost/preprocessed.pkl\"\n",
    "preprocess_and_save_dataset(dataset_path, preprocessed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_output_path = \"selfpost/vectorized.npy\"\n",
    "vectorized_labels_output_path = \"selfpost/vectorized_labels.npy\"\n",
    "vectorize_and_save_dataset(preprocessed_path, vectorized_output_path, vectorized_labels_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class LinearModel(ModelWrap):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.last_loss = 0\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.model.train(X,y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def get_last_loss(self, X_train, y_train):\n",
    "        return log_loss(y_train, model.predict_proba(X_train), eps=1e-15)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "\n",
    "class ConfidenceSamplingSuggestion(ActiveLearningBase):\n",
    "    def __init__(self, n_top=1000):\n",
    "        self.n_top = n_top\n",
    "\n",
    "    def get_samples_for_labeling(self, model, X_test, y_test):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        y_proba = np.max(y_proba, axis=1)\n",
    "        ind = np.lexsort((y_test, y_proba))\n",
    "        return \"oracle\", ind[:min(self.n_top, y_proba.shape[0])]\n",
    "\n",
    "class MarginSampling(ActiveLearningBase):\n",
    "    def __init__(self, n_top=1000):\n",
    "        self.n_top = n_top\n",
    "        \n",
    "    def get_samples_for_labeling(self, model, X_test, y_test):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        y_proba = np.sort(y_proba, axis=1)[:,::-1]\n",
    "        y_proba = y_proba[:,0] - y_proba[:,1]\n",
    "        ind = np.lexsort((y_test, y_proba))\n",
    "        return \"oracle\", ind[:min(self.n_top, y_proba.shape[0])]\n",
    "\n",
    "class EntropySampling(ActiveLearningBase):\n",
    "    def __init__(self, n_top=1000):\n",
    "        self.n_top = n_top\n",
    "        \n",
    "    def get_samples_for_labeling(self, model, X_test, y_test):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        y_proba = entropy(y_proba, axis=1)\n",
    "        ind = np.lexsort((y_test, y_proba))[::-1]\n",
    "        print(y_proba[ind[0]], y_proba[ind[-1]])\n",
    "        return \"oracle\", ind[:min(self.n_top, y_proba.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "vectorized_output_path = \"selfpost/vectorized.npy\"\n",
    "vectorized_labels_output_path = \"selfpost/vectorized_labels.npy\"\n",
    "with open(vectorized_output_path, \"rb\") as vect_X, open(vectorized_labels_output_path, \"rb\") as vect_y:\n",
    "    X = np.load(vect_X, allow_pickle=True)\n",
    "    y = np.load(vect_y, allow_pickle=True)\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "del le\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2fb12d4e3baf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"selfpost/models/logreg_100it\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = \"selfpost/models/logreg_100it\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=random_seed)\n",
    "model = LogisticRegression(random_state=random_seed, n_jobs=-1, verbose=True)\n",
    "model.fit(X_train, y_train)\n",
    "dump(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.06228423,  0.06092767, -0.14749891, ..., -0.3225482 ,\n",
       "          0.14105452,  0.00854856],\n",
       "        [ 0.08068533, -0.02982698, -0.12298278, ..., -0.27350412,\n",
       "          0.05903656,  0.0867618 ],\n",
       "        [ 0.03988495,  0.06417522, -0.20442137, ..., -0.29071138,\n",
       "          0.03378086, -0.01860267],\n",
       "        ...,\n",
       "        [ 0.15182757,  0.10873834, -0.17133273, ..., -0.17019229,\n",
       "          0.15758706,  0.04102596],\n",
       "        [ 0.04931326,  0.03915333, -0.15517242, ..., -0.30393526,\n",
       "          0.0845803 , -0.00351562],\n",
       "        [ 0.09860376,  0.01065233, -0.13773885, ..., -0.28388423,\n",
       "          0.1883342 , -0.11135513]]),\n",
       " array([470, 445, 853, ...,   9, 288, 667]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"selfpost/models/logreg_100it\"\n",
    "model = load(model_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=random_seed)\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrappedModel = LinearModel(model)\n",
    "confSuggest = ConfidenceSamplingSuggestion(10000)\n",
    "sampl_ind = rng.choice(X_test.shape[0], 1000, replace=False)\n",
    "ind = confSuggest.get_samples_for_labeling(model, X_test[sampl_ind, :], y_test[sampl_ind])\n",
    "\n",
    "print(sampl_ind[ind[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  1],\n",
       "       [10, -2],\n",
       "       [ 1,  0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1, 1], [2, 1]])\n",
    "test_y = np.array([2, 4])\n",
    "\n",
    "y_labels = np.array([1, 2, 3])\n",
    "y_proba = np.array([[1, 0], [111, 1], [10, -2]])\n",
    "y_proba = entropy(y_proba, axis=1)\n",
    "ind = np.lexsort((y_proba, y_proba))\n",
    "print(ind)\n",
    "\n",
    "y_proba = np.array([[1, 0], [111, 1], [10, -2]])\n",
    "\n",
    "test = np.append(test, y_proba[ind[0:2]], axis=0)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "sug = Suggester(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Looking at 8102 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7792310653056544 8.090449338436718e-13\n"
     ]
    }
   ],
   "source": [
    "suggest_alg = EntropySampling(100)\n",
    "sug.active_learning_suggest(suggest_alg, LinearModel(model), sample_ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([263663, 556963, 162239,  32687, 534678, 123910, 376963, 676468,\n",
       "       232583, 569997, 102716, 393583, 645799, 105063, 738217, 767381,\n",
       "       723656, 759143, 378407, 476941,  88606, 138546, 295977, 376829,\n",
       "       185133, 183306, 299197, 167503, 128336, 406411, 341994, 229912,\n",
       "       322558, 309247, 102168, 161123, 167053, 782591, 624216, 293301,\n",
       "       495366, 319562, 602956,   5770, 205171, 627581, 189452, 194699,\n",
       "       532958,   8917, 637468, 141753, 375895, 306330, 312546, 410753,\n",
       "        36320, 772195, 399059, 795146, 142815, 580262, 405912,  42023,\n",
       "       635218,   4919, 788857, 644924, 772022, 780991, 498361, 464755,\n",
       "       586466,  40846, 517110, 786113, 320149, 306214, 610751, 782525,\n",
       "       162965, 274700,  36375, 181143, 406103, 693918, 799682, 768447,\n",
       "       142749,  46536, 604493,  93185, 282442, 147943, 483390, 623975,\n",
       "       197345, 522718, 629541, 210976])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sug.last_suggest.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 300), (202800, 300), (810200, 300))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_to_move = sug.X_test[sug.last_suggest.indices]\n",
    "samples_to_move.shape, sug.X_train.shape, sug.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sug.apply_last_suggest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202900, 300), (810100, 300))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sug.X_train.shape, sug.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoLabeling(ActiveLearningBase):\n",
    "    def __init__(self, n_top=1000):\n",
    "        self.n_top = n_top\n",
    "\n",
    "    def get_samples_for_labeling(self, model, X_test, y_test):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        max_ind = np.argmax(y_proba, axis=1)\n",
    "        y_proba = np.max(y_proba, axis=1)\n",
    "        ind = np.lexsort((max_ind, y_proba))[::-1]\n",
    "        ind_to_return = ind[:min(self.n_top, y_proba.shape[0])]\n",
    "        return \"relabeling\", ind_to_return, max_ind[ind_to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Looking at 8104 samples from test.\n"
     ]
    }
   ],
   "source": [
    "suggest_alg = PseudoLabeling(100)\n",
    "sug.active_learning_suggest(suggest_alg, LinearModel(model), sample_ratio=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_move = sug.X_test[sug.last_suggest.indices]\n",
    "samples_to_move.shape, sug.X_train.shape, sug.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is no new unapplied suggests available. Aborting.\n"
     ]
    }
   ],
   "source": [
    "sug.apply_last_suggest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark our solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_output_path = \"selfpost/vectorized.npy\"\n",
    "vectorized_labels_output_path = \"selfpost/vectorized_labels.npy\"\n",
    "with open(vectorized_output_path, \"rb\") as vect_X, open(vectorized_labels_output_path, \"rb\") as vect_y:\n",
    "    X = np.load(vect_X, allow_pickle=True)\n",
    "    y = np.load(vect_y, allow_pickle=True)\n",
    "model_path = \"selfpost/models/logreg_100it\"\n",
    "model = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Looking at 81040 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5454084402764067, 'f1_score': 0.5411580561102263, 'precision_score': 0.5616867560333363, 'recall_score': 0.5460126540293783}\n",
      "(810400, 300) (810400,)\n",
      "(800400, 300) (800400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 29.2min finished\n",
      "INFO:root:Looking at 80040 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.546228135932034, 'f1_score': 0.5417091029620242, 'precision_score': 0.5615681180355546, 'recall_score': 0.5465371881251833}\n",
      "(790400, 300) (790400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "sug = Suggester(X,y)\n",
    "suggest_alg = ActiveLearning.EntropySampling(10000)\n",
    "epochs = 5\n",
    "print(sug.evaluate_metrics(LinearModel(model)))\n",
    "print(sug.X_test.shape, sug.y_test.shape)\n",
    "for ep in range(epochs):\n",
    "    sug.active_learning_suggest(suggest_alg, LinearModel(model), sample_ratio=0.1)\n",
    "    sug.apply_last_suggest()\n",
    "    print(sug.X_test.shape, sug.y_test.shape)\n",
    "    model.fit(sug.X_train, sug.y_train)\n",
    "    print(sug.evaluate_metrics(LinearModel(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It actually took too long to train logreg from sklearn. I am going to implement one with pytorch to train on cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "class LogReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(300, 1013),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "def worker_init_fn(x):\n",
    "    seed = args.seed + x\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    return\n",
    "\n",
    "\n",
    "class LinearModelTorch(ModelWrap):\n",
    "    def __init__(self, model, itr):\n",
    "        self.model = model\n",
    "        self.last_loss = 0\n",
    "        self.iter = itr\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        torch.cuda.empty_cache()\n",
    "        X = torch.from_numpy(X.astype(np.float32))\n",
    "        y = torch.from_numpy(y.astype(np.int64))\n",
    "        self.model = self.model.cuda()\n",
    "        self.model.train()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-2, weight_decay=1e-5)\n",
    "        criterion = nn.NLLLoss()\n",
    "        dataset = TensorDataset(X, y)\n",
    "        dataloader = DataLoader(dataset, batch_size=10000, num_workers=0)\n",
    "        for epoch in tqdm(range(self.iter)):\n",
    "            for bX, by in dataloader:\n",
    "                bX = bX.view(-1, 300)\n",
    "                bX = bX.cuda()\n",
    "                by = by.cuda()\n",
    "                torch.cuda.manual_seed(random_seed)\n",
    "                optimizer.zero_grad()\n",
    "                torch.cuda.manual_seed(random_seed)\n",
    "                output = self.model(bX)\n",
    "                loss = criterion(output, by)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "#             if (epoch % 10 == 0):\n",
    "#                 print(f\"ep{epoch}: {loss}\")\n",
    "            torch.cuda.empty_cache()\n",
    "        X = X.cpu().detach().numpy()\n",
    "        y = y.cpu().detach().numpy()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.view(-1, 300)\n",
    "        X = X.cpu()\n",
    "        self.model = self.model.cpu()\n",
    "        self.model = self.model.eval()\n",
    "        result = torch.argmax(self.model(X.float()), axis=1)\n",
    "        X = X.detach().numpy()\n",
    "        return result.detach().numpy()\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = torch.from_numpy(X)\n",
    "        X = X.view(-1, 300)\n",
    "        X = X.cpu()\n",
    "        result = torch.exp(self.model(X.float()))\n",
    "        X = X.detach().numpy()\n",
    "        return result.detach().numpy()\n",
    "    \n",
    "    def get_last_loss(self, X_train, y_train):\n",
    "        return log_loss(y_train, self.model.predict_proba(X_train), eps=1e-15)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:43<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "random.seed(random_seed)\n",
    "\n",
    "model = LinearModelTorch(LogReg(), 100)\n",
    "model.train(X_train, y_train.astype(np.int64))\n",
    "# print(sug.evaluate_metrics(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"selfpost/models/logreg_torch1000it\"\n",
    "torch.save(model.model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"selfpost/models/logreg_torch1000it\"\n",
    "model = LogReg()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model = LinearModelTorch(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load training data by batches.\n",
    "from torch.utils.data import IterableDataset\n",
    "class IterDataset(IterableDataset):\n",
    "    def __init__(self, filename, chunksize):\n",
    "        self.filename = filename\n",
    "        self.chunksize = chunksize\n",
    "        \n",
    "    def __iter__(self):\n",
    "        csv = pd.read_csv(self.filename, chunksize=self.chunksize)\n",
    "        for chunk in csv:\n",
    "            y = chunk[\"label\"]\n",
    "            X = chunk[\"features\"]\n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 153.14it/s]\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.70it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.12032314939611104, 'f1_score': 0.08011109207989375, 'precision_score': 0.16564131417792763, 'recall_score': 0.12334363050572518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:33<00:00,  2.98it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.1761947433453328, 'f1_score': 0.1435605994590661, 'precision_score': 0.3220889701125707, 'recall_score': 0.17948055805536103}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:54<00:00,  1.83it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.20563095924629224, 'f1_score': 0.17587917126308947, 'precision_score': 0.35339331627805903, 'recall_score': 0.21121393444142386}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:09<00:00,  1.45it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.250815730262332, 'f1_score': 0.21925739638517897, 'precision_score': 0.40163269304307286, 'recall_score': 0.25717202419174234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.2718777789595685, 'f1_score': 0.23986938423568663, 'precision_score': 0.42225925440403356, 'recall_score': 0.28008372187732206}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "random.seed(random_seed)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "sug = Suggester(X,y, test_size=0.999)\n",
    "suggest_alg = ActiveLearning.EntropySampling(20000)\n",
    "epochs = 5\n",
    "model = LinearModelTorch(LogReg(), 100)\n",
    "model.train(sug.X_train, sug.y_train)\n",
    "print(sug.evaluate_metrics(model))\n",
    "for ep in range(epochs):\n",
    "    sug.active_learning_suggest(suggest_alg, model, sample_ratio=1)\n",
    "    sug.apply_last_suggest()\n",
    "    model = LinearModelTorch(LogReg(), 100)\n",
    "    model.train(sug.X_train, sug.y_train)\n",
    "    print(sug.evaluate_metrics(model)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 141.44it/s]\n",
      "C:\\Users\\TOPAPEC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.59it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.25758603691379023, 'f1_score': 0.2295162463024065, 'precision_score': 0.3802541015988504, 'recall_score': 0.25801296594211937}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:35<00:00,  2.85it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.3651293690141946, 'f1_score': 0.3467491736553693, 'precision_score': 0.46386106952914696, 'recall_score': 0.3656973686331774}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:51<00:00,  1.95it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.42716969874588623, 'f1_score': 0.4141080949884524, 'precision_score': 0.4931442420478847, 'recall_score': 0.427722552321968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.45980469684662983, 'f1_score': 0.4494874504307956, 'precision_score': 0.5124286969425367, 'recall_score': 0.46034060871317634}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:27<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.4784958557523298, 'f1_score': 0.46862981783226004, 'precision_score': 0.523155552472409, 'recall_score': 0.4790782979829941}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "random.seed(random_seed)\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "sug = Suggester(X,y, test_size=0.999)\n",
    "suggest_alg = ActiveLearning.RandomSampling(20000)\n",
    "epochs = 5\n",
    "model = LinearModelTorch(LogReg(), 100)\n",
    "model.train(sug.X_train, sug.y_train)\n",
    "print(sug.evaluate_metrics(model))\n",
    "for ep in range(epochs):\n",
    "    sug.active_learning_suggest(suggest_alg, model, sample_ratio=1)\n",
    "    sug.apply_last_suggest()\n",
    "    model = LinearModelTorch(LogReg(), 100)\n",
    "    model.train(sug.X_train, sug.y_train)\n",
    "    print(sug.evaluate_metrics(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sampling(sampling):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.use_deterministic_algorithms(False)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    sug = Suggester(X,y, test_size=0.999)\n",
    "    suggest_alg = sampling(20000)\n",
    "    epochs = 5\n",
    "    model = LinearModelTorch(LogReg(), 100)\n",
    "    model.train(sug.X_train, sug.y_train)\n",
    "    print(sug.evaluate_metrics(model))\n",
    "    for ep in range(epochs):\n",
    "        sug.active_learning_suggest(suggest_alg, model, sample_ratio=1)\n",
    "        sug.apply_last_suggest()\n",
    "        model = LinearModelTorch(LogReg(), 100)\n",
    "        model.train(sug.X_train, sug.y_train)\n",
    "        print(sug.evaluate_metrics(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 135.32it/s]\n",
      "C:\\Users\\TOPAPEC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.91it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.25758603691379023, 'f1_score': 0.2295162463024065, 'precision_score': 0.3802541015988504, 'recall_score': 0.25801296594211937}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:39<00:00,  2.56it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.3651293690141946, 'f1_score': 0.3467491736553693, 'precision_score': 0.46386106952914696, 'recall_score': 0.3656973686331774}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:57<00:00,  1.74it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.42716969874588623, 'f1_score': 0.4141080949884524, 'precision_score': 0.4931442420478847, 'recall_score': 0.427722552321968}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.45980469684662983, 'f1_score': 0.4494874504307956, 'precision_score': 0.5124286969425367, 'recall_score': 0.46034060871317634}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:35<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.4784958557523298, 'f1_score': 0.46862981783226004, 'precision_score': 0.523155552472409, 'recall_score': 0.4790782979829941}\n"
     ]
    }
   ],
   "source": [
    "test_sampling(ActiveLearning.RandomSampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 148.59it/s]\n",
      "C:\\Users\\TOPAPEC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.93it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.20885757575452096, 'f1_score': 0.1713918650357639, 'precision_score': 0.31880790131829706, 'recall_score': 0.20964201571115237}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:39<00:00,  2.53it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.29544119417235004, 'f1_score': 0.2812895706903934, 'precision_score': 0.4518881159402032, 'recall_score': 0.29597843118867534}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:58<00:00,  1.71it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.3730071944259743, 'f1_score': 0.3646671354662496, 'precision_score': 0.4906963135925287, 'recall_score': 0.3731876283867597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.42011852096649416, 'f1_score': 0.4202663346567754, 'precision_score': 0.5037458470077114, 'recall_score': 0.41979518849104924}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:34<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.4530810197952383, 'f1_score': 0.4558394587601572, 'precision_score': 0.5246939914541863, 'recall_score': 0.45223207448474995}\n"
     ]
    }
   ],
   "source": [
    "test_sampling(ActiveLearning.MarginSamplinxg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 155.15it/s]\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:19<00:00,  5.08it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.12032314939611104, 'f1_score': 0.08011109207989375, 'precision_score': 0.16564131417792763, 'recall_score': 0.12334363050572518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:37<00:00,  2.64it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.1761947433453328, 'f1_score': 0.1435605994590661, 'precision_score': 0.3220889701125707, 'recall_score': 0.17948055805536103}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:57<00:00,  1.75it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.20563095924629224, 'f1_score': 0.17587917126308947, 'precision_score': 0.35339331627805903, 'recall_score': 0.21121393444142386}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.250815730262332, 'f1_score': 0.21925739638517897, 'precision_score': 0.40163269304307286, 'recall_score': 0.25717202419174234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:38<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.2718777789595685, 'f1_score': 0.23986938423568663, 'precision_score': 0.42225925440403356, 'recall_score': 0.28008372187732206}\n"
     ]
    }
   ],
   "source": [
    "test_sampling(ActiveLearning.EntropySampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 151.52it/s]\n",
      "C:\\Users\\TOPAPEC\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:19<00:00,  5.05it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.12348448114743439, 'f1_score': 0.08120031715059717, 'precision_score': 0.14956190363376695, 'recall_score': 0.12647391339714645}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:40<00:00,  2.49it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.1864263616694462, 'f1_score': 0.1584124212508903, 'precision_score': 0.33191636161012233, 'recall_score': 0.1891674600090658}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:58<00:00,  1.70it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.22465012652483698, 'f1_score': 0.19963730701523458, 'precision_score': 0.3805215460811074, 'recall_score': 0.2287199787284282}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.28668962120716274, 'f1_score': 0.2668259998297966, 'precision_score': 0.43653398161855067, 'recall_score': 0.29104322356700546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:39<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.3230221483420268, 'f1_score': 0.30471003897422383, 'precision_score': 0.4644152379266481, 'recall_score': 0.3281183018721371}\n"
     ]
    }
   ],
   "source": [
    "test_samplingt_sampling(ActiveLearning.ConfidenceSamplingSuggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 149.03it/s]\n",
      "INFO:root:Looking at 1011987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.06928152239109792, 'f1_score': 0.04668933198411252, 'precision_score': 0.0905574345581354, 'recall_score': 0.06937743446586983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:20<00:00,  4.83it/s]\n",
      "INFO:root:Looking at 991987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.047714334966083224, 'f1_score': 0.02743961741807955, 'precision_score': 0.05530317286837833, 'recall_score': 0.04980937577977587}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:40<00:00,  2.46it/s]\n",
      "INFO:root:Looking at 971987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.03425560218397983, 'f1_score': 0.01927343391226129, 'precision_score': 0.051314444957531916, 'recall_score': 0.03820572043909834}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:02<00:00,  1.60it/s]\n",
      "INFO:root:Looking at 951987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.026843853960190633, 'f1_score': 0.01507116066391142, 'precision_score': 0.048106576126196045, 'recall_score': 0.03191526053884242}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23it/s]\n",
      "INFO:root:Looking at 931987 samples from test.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.022224558926251116, 'f1_score': 0.01265036136148406, 'precision_score': 0.04218539275659873, 'recall_score': 0.027715996198391497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.019238212825402116, 'f1_score': 0.01108025426126459, 'precision_score': 0.03880440281425076, 'recall_score': 0.024817215785548453}\n"
     ]
    }
   ],
   "source": [
    "test_sampling(ActiveLearning.PseudoLabeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindIndistinguishableObjectInTrain(ActiveLearningBase):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def build_class_confusion_dict(self, y_pred, y_train):\n",
    "#         {\"a-b\":100, \"b-c\":10, ...}\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def get_samples_for_labeling(self, model, X_train, y_train):\n",
    "        logging.Info(\"Class a and b were confused 1000 times in total. To relabel them to class a-b apply this suggest...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimated Error Reduction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 11), (1599,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import modules\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from modules.models.Wraps import TorchClassifierWrap\n",
    "from modules.models.Linear import LogReg\n",
    "importlib.reload(modules.models.Wraps)\n",
    "importlib.reload(modules.models.Linear)\n",
    "\n",
    "\n",
    "\n",
    "# https://archive.ics.uci.edu/ml/datasets/Wine+Quality - red wine quality\n",
    "wineq = pd.read_csv(\"tmp/datasets/winequality.csv\", sep=\";\")\n",
    "\n",
    "X = wineq.drop(\"quality\", axis=1)\n",
    "y = wineq[\"quality\"]\n",
    "classes = np.unique(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.999, random_state=42)\n",
    "X_pool, X_val, y_pool, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectedErrorReduction(sample, classes, X_train, y_train, base_model):\n",
    "    eer = 0.0\n",
    "    for cls in classes:\n",
    "        model = TorchClassifierWrap(LogReg(X_train.shape[1], len(classes)), 100, X_train.shape[1], X_train.shape[0])\n",
    "        X_append = np.asarray([sample for i in range(len(classes))]).reshape((len(classes), X_train.shape[1]))\n",
    "        y_append = np.asarray([cls for cls in classes]).reshape((len(classes)))\n",
    "        X_new = np.append(X_train, X_append, axis=0)\n",
    "        y_new = np.append(y_train, y_append, axis=0)\n",
    "        model.fit(X_new, y_new)\n",
    "        proba = model.predict_proba(X_append)\n",
    "        loss = float(nn.NLLLoss()(torch.tensor(proba), torch.tensor(y_append, dtype=torch.int64)))\n",
    "        print(loss)\n",
    "        err += loss * base_model.predict_proba[cls]\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EERsampling(X_train, y_train, X_pool, y_pool, X_val, y_val, itr):\n",
    "    classes = np.unique(y_train)\n",
    "    model = TorchClassifierWrap(LogReg(X_train.shape[1], len(classes)), 100, X_train.shape[1], 10)\n",
    "    metrics = []\n",
    "    for iteration in tqdm(range(itr)):\n",
    "        sample_ind = np.random.choice(self.X_test.shape[0], num_of_elements, replace=False)\n",
    "        loss_reduction = np.ones((sample_ind.shape[0]))\n",
    "        for i, sample in enumerate(X_pool[sample_ind]):\n",
    "            loss_reduction[i] = expectedErrorReduction(sample, classes, X_train, y_train, model)\n",
    "        print(loss_reduction)\n",
    "        srt = np.argsort(loss_reduction)\n",
    "        X_train = np.append(X_train, X_pool[srt[0]], axis=0)\n",
    "        y_train = np.append(y_train, y_pool[srt[0]], axis=0)\n",
    "        X_pool = np.delete(X_pool, srt[0], axis=0)\n",
    "        y_pool = np.delete(y_pool, srt[0], axis=0)\n",
    "        model = TorchClassifierWrap(LogReg(X_train.shape[1], len(classes)), 100, X_train.shape[1], 10)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        metrics.append(precision_score(y_pred, y_val, average=\"macro\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6 into shape (6,11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b9444f5307b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEERsampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-5ae46b513759>\u001b[0m in \u001b[0;36mEERsampling\u001b[1;34m(X_train, y_train, X_pool, y_pool, X_val, y_val, itr)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mloss_reduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mloss_reduction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpectedErrorReduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_reduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_reduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-68b963a207ba>\u001b[0m in \u001b[0;36mexpectedErrorReduction\u001b[1;34m(sample, classes, X_train, y_train, base_model)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTorchClassifierWrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogReg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mX_append\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0my_append\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mX_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_append\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 6 into shape (6,11)"
     ]
    }
   ],
   "source": [
    "EERsampling(X_train, y_train, X_pool, y_pool, X_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Randomsampling(X_train, y_train, X_pool, y_pool, X_val, y_val, itr):\n",
    "    classes = np.unique(y_train)\n",
    "    metrics = []\n",
    "    for iteration in tqdm(range(itr)):\n",
    "        loss_reduction = np.ones((X_pool.shape))\n",
    "        for i, sample in enumerate(X_pool):\n",
    "            loss_reduction[i] = np.random.random_sample()\n",
    "        print(loss_reduction)\n",
    "        srt = np.argsort(loss_reduction)\n",
    "        X_train = np.append(X_train, X_pool[srt[0]], axis=0)\n",
    "        y_train = np.append(y_train, y_pool[srt[0]], axis=0)\n",
    "        X_pool = np.delete(X_pool, srt[0], axis=0)\n",
    "        y_pool = np.delete(y_pool, srt[0], axis=0)\n",
    "        model = TorchClassifierWrap(LogReg(X_train.shape[1], len(classes)), 100, X_train.shape[1], 10)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        metrics.append(precision_score(y_pred, y_val, average=\"macro\"))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]\n",
      " [0.19871568 0.19871568 0.19871568 0.19871568]\n",
      " [0.00552212 0.00552212 0.00552212 0.00552212]\n",
      " [0.81546143 0.81546143 0.81546143 0.81546143]\n",
      " [0.70685734 0.70685734 0.70685734 0.70685734]\n",
      " [0.72900717 0.72900717 0.72900717 0.72900717]\n",
      " [0.77127035 0.77127035 0.77127035 0.77127035]\n",
      " [0.07404465 0.07404465 0.07404465 0.07404465]\n",
      " [0.35846573 0.35846573 0.35846573 0.35846573]\n",
      " [0.11586906 0.11586906 0.11586906 0.11586906]\n",
      " [0.86310343 0.86310343 0.86310343 0.86310343]\n",
      " [0.62329813 0.62329813 0.62329813 0.62329813]\n",
      " [0.33089802 0.33089802 0.33089802 0.33089802]\n",
      " [0.06355835 0.06355835 0.06355835 0.06355835]\n",
      " [0.31098232 0.31098232 0.31098232 0.31098232]\n",
      " [0.32518332 0.32518332 0.32518332 0.32518332]\n",
      " [0.72960618 0.72960618 0.72960618 0.72960618]\n",
      " [0.63755747 0.63755747 0.63755747 0.63755747]\n",
      " [0.88721274 0.88721274 0.88721274 0.88721274]\n",
      " [0.47221493 0.47221493 0.47221493 0.47221493]\n",
      " [0.11959425 0.11959425 0.11959425 0.11959425]\n",
      " [0.71324479 0.71324479 0.71324479 0.71324479]\n",
      " [0.76078505 0.76078505 0.76078505 0.76078505]\n",
      " [0.5612772  0.5612772  0.5612772  0.5612772 ]\n",
      " [0.77096718 0.77096718 0.77096718 0.77096718]]\n",
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]\n",
      " [0.19871568 0.19871568 0.19871568 0.19871568]\n",
      " [0.00552212 0.00552212 0.00552212 0.00552212]\n",
      " [0.81546143 0.81546143 0.81546143 0.81546143]\n",
      " [0.70685734 0.70685734 0.70685734 0.70685734]\n",
      " [0.72900717 0.72900717 0.72900717 0.72900717]\n",
      " [0.77127035 0.77127035 0.77127035 0.77127035]\n",
      " [0.07404465 0.07404465 0.07404465 0.07404465]\n",
      " [0.35846573 0.35846573 0.35846573 0.35846573]\n",
      " [0.11586906 0.11586906 0.11586906 0.11586906]\n",
      " [0.86310343 0.86310343 0.86310343 0.86310343]\n",
      " [0.62329813 0.62329813 0.62329813 0.62329813]\n",
      " [0.33089802 0.33089802 0.33089802 0.33089802]\n",
      " [0.06355835 0.06355835 0.06355835 0.06355835]\n",
      " [0.31098232 0.31098232 0.31098232 0.31098232]\n",
      " [0.32518332 0.32518332 0.32518332 0.32518332]\n",
      " [0.72960618 0.72960618 0.72960618 0.72960618]\n",
      " [0.63755747 0.63755747 0.63755747 0.63755747]\n",
      " [0.88721274 0.88721274 0.88721274 0.88721274]\n",
      " [0.47221493 0.47221493 0.47221493 0.47221493]\n",
      " [0.11959425 0.11959425 0.11959425 0.11959425]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:00,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]\n",
      " [0.19871568 0.19871568 0.19871568 0.19871568]\n",
      " [0.00552212 0.00552212 0.00552212 0.00552212]\n",
      " [0.81546143 0.81546143 0.81546143 0.81546143]\n",
      " [0.70685734 0.70685734 0.70685734 0.70685734]\n",
      " [0.72900717 0.72900717 0.72900717 0.72900717]\n",
      " [0.77127035 0.77127035 0.77127035 0.77127035]\n",
      " [0.07404465 0.07404465 0.07404465 0.07404465]\n",
      " [0.35846573 0.35846573 0.35846573 0.35846573]\n",
      " [0.11586906 0.11586906 0.11586906 0.11586906]\n",
      " [0.86310343 0.86310343 0.86310343 0.86310343]\n",
      " [0.62329813 0.62329813 0.62329813 0.62329813]\n",
      " [0.33089802 0.33089802 0.33089802 0.33089802]\n",
      " [0.06355835 0.06355835 0.06355835 0.06355835]\n",
      " [0.31098232 0.31098232 0.31098232 0.31098232]\n",
      " [0.32518332 0.32518332 0.32518332 0.32518332]\n",
      " [0.72960618 0.72960618 0.72960618 0.72960618]]\n",
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]\n",
      " [0.19871568 0.19871568 0.19871568 0.19871568]\n",
      " [0.00552212 0.00552212 0.00552212 0.00552212]\n",
      " [0.81546143 0.81546143 0.81546143 0.81546143]\n",
      " [0.70685734 0.70685734 0.70685734 0.70685734]\n",
      " [0.72900717 0.72900717 0.72900717 0.72900717]\n",
      " [0.77127035 0.77127035 0.77127035 0.77127035]\n",
      " [0.07404465 0.07404465 0.07404465 0.07404465]\n",
      " [0.35846573 0.35846573 0.35846573 0.35846573]\n",
      " [0.11586906 0.11586906 0.11586906 0.11586906]\n",
      " [0.86310343 0.86310343 0.86310343 0.86310343]\n",
      " [0.62329813 0.62329813 0.62329813 0.62329813]\n",
      " [0.33089802 0.33089802 0.33089802 0.33089802]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:00<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]\n",
      " [0.19871568 0.19871568 0.19871568 0.19871568]\n",
      " [0.00552212 0.00552212 0.00552212 0.00552212]\n",
      " [0.81546143 0.81546143 0.81546143 0.81546143]\n",
      " [0.70685734 0.70685734 0.70685734 0.70685734]\n",
      " [0.72900717 0.72900717 0.72900717 0.72900717]\n",
      " [0.77127035 0.77127035 0.77127035 0.77127035]\n",
      " [0.07404465 0.07404465 0.07404465 0.07404465]\n",
      " [0.35846573 0.35846573 0.35846573 0.35846573]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:00<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]\n",
      " [0.19871568 0.19871568 0.19871568 0.19871568]\n",
      " [0.00552212 0.00552212 0.00552212 0.00552212]\n",
      " [0.81546143 0.81546143 0.81546143 0.81546143]\n",
      " [0.70685734 0.70685734 0.70685734 0.70685734]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:01<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]\n",
      " [0.80219698 0.80219698 0.80219698 0.80219698]\n",
      " [0.07455064 0.07455064 0.07455064 0.07455064]\n",
      " [0.98688694 0.98688694 0.98688694 0.98688694]\n",
      " [0.77224477 0.77224477 0.77224477 0.77224477]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:01<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]\n",
      " [0.35675333 0.35675333 0.35675333 0.35675333]\n",
      " [0.28093451 0.28093451 0.28093451 0.28093451]\n",
      " [0.54269608 0.54269608 0.54269608 0.54269608]\n",
      " [0.14092422 0.14092422 0.14092422 0.14092422]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:01<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]\n",
      " [0.32533033 0.32533033 0.32533033 0.32533033]\n",
      " [0.38867729 0.38867729 0.38867729 0.38867729]\n",
      " [0.27134903 0.27134903 0.27134903 0.27134903]\n",
      " [0.82873751 0.82873751 0.82873751 0.82873751]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:02<00:00,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37454012 0.37454012 0.37454012 0.37454012]\n",
      " [0.95071431 0.95071431 0.95071431 0.95071431]\n",
      " [0.73199394 0.73199394 0.73199394 0.73199394]\n",
      " [0.59865848 0.59865848 0.59865848 0.59865848]\n",
      " [0.15601864 0.15601864 0.15601864 0.15601864]\n",
      " [0.15599452 0.15599452 0.15599452 0.15599452]\n",
      " [0.05808361 0.05808361 0.05808361 0.05808361]\n",
      " [0.86617615 0.86617615 0.86617615 0.86617615]\n",
      " [0.60111501 0.60111501 0.60111501 0.60111501]\n",
      " [0.70807258 0.70807258 0.70807258 0.70807258]\n",
      " [0.02058449 0.02058449 0.02058449 0.02058449]\n",
      " [0.96990985 0.96990985 0.96990985 0.96990985]\n",
      " [0.83244264 0.83244264 0.83244264 0.83244264]\n",
      " [0.21233911 0.21233911 0.21233911 0.21233911]\n",
      " [0.18182497 0.18182497 0.18182497 0.18182497]\n",
      " [0.18340451 0.18340451 0.18340451 0.18340451]\n",
      " [0.30424224 0.30424224 0.30424224 0.30424224]\n",
      " [0.52475643 0.52475643 0.52475643 0.52475643]\n",
      " [0.43194502 0.43194502 0.43194502 0.43194502]\n",
      " [0.29122914 0.29122914 0.29122914 0.29122914]\n",
      " [0.61185289 0.61185289 0.61185289 0.61185289]\n",
      " [0.13949386 0.13949386 0.13949386 0.13949386]\n",
      " [0.29214465 0.29214465 0.29214465 0.29214465]\n",
      " [0.36636184 0.36636184 0.36636184 0.36636184]\n",
      " [0.45606998 0.45606998 0.45606998 0.45606998]\n",
      " [0.78517596 0.78517596 0.78517596 0.78517596]\n",
      " [0.19967378 0.19967378 0.19967378 0.19967378]\n",
      " [0.51423444 0.51423444 0.51423444 0.51423444]\n",
      " [0.59241457 0.59241457 0.59241457 0.59241457]\n",
      " [0.04645041 0.04645041 0.04645041 0.04645041]\n",
      " [0.60754485 0.60754485 0.60754485 0.60754485]\n",
      " [0.17052412 0.17052412 0.17052412 0.17052412]\n",
      " [0.06505159 0.06505159 0.06505159 0.06505159]\n",
      " [0.94888554 0.94888554 0.94888554 0.94888554]\n",
      " [0.96563203 0.96563203 0.96563203 0.96563203]\n",
      " [0.80839735 0.80839735 0.80839735 0.80839735]\n",
      " [0.30461377 0.30461377 0.30461377 0.30461377]\n",
      " [0.09767211 0.09767211 0.09767211 0.09767211]\n",
      " [0.68423303 0.68423303 0.68423303 0.68423303]\n",
      " [0.44015249 0.44015249 0.44015249 0.44015249]\n",
      " [0.12203823 0.12203823 0.12203823 0.12203823]\n",
      " [0.49517691 0.49517691 0.49517691 0.49517691]\n",
      " [0.03438852 0.03438852 0.03438852 0.03438852]\n",
      " [0.9093204  0.9093204  0.9093204  0.9093204 ]\n",
      " [0.25877998 0.25877998 0.25877998 0.25877998]\n",
      " [0.66252228 0.66252228 0.66252228 0.66252228]\n",
      " [0.31171108 0.31171108 0.31171108 0.31171108]\n",
      " [0.52006802 0.52006802 0.52006802 0.52006802]\n",
      " [0.54671028 0.54671028 0.54671028 0.54671028]\n",
      " [0.18485446 0.18485446 0.18485446 0.18485446]\n",
      " [0.96958463 0.96958463 0.96958463 0.96958463]\n",
      " [0.77513282 0.77513282 0.77513282 0.77513282]\n",
      " [0.93949894 0.93949894 0.93949894 0.93949894]\n",
      " [0.89482735 0.89482735 0.89482735 0.89482735]\n",
      " [0.59789998 0.59789998 0.59789998 0.59789998]\n",
      " [0.92187424 0.92187424 0.92187424 0.92187424]\n",
      " [0.0884925  0.0884925  0.0884925  0.0884925 ]\n",
      " [0.19598286 0.19598286 0.19598286 0.19598286]\n",
      " [0.04522729 0.04522729 0.04522729 0.04522729]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6862745098039215,\n",
       " 0.7058823529411765,\n",
       " 0.8941176470588236,\n",
       " 0.9441176470588234,\n",
       " 0.823529411764706,\n",
       " 0.9333333333333332,\n",
       " 0.7058823529411765,\n",
       " 0.8431372549019608,\n",
       " 0.9833333333333334,\n",
       " 0.9411764705882352]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Randomsampling(X_train, y_train, X_pool, y_pool, X_val, y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
